using Microsoft.Extensions.Logging;
using Microsoft.UI.Xaml.Input;
using Windows.ApplicationModel.Resources;
using XiaoZhi.Core.Constants;
using XiaoZhi.Core.Interfaces;
using XiaoZhi.Core.Models;
using XiaoZhi.Core.Services;

namespace XiaoZhi.WinUI.Views;

/// <summary>
/// é¦–é¡µ - è¯­éŸ³å¯¹è¯ç•Œé¢
/// </summary>
public sealed partial class HomePage : Page
{
    private readonly ILogger<HomePage>? _logger;
    private readonly IVoiceChatService? _voiceChatService;
    private readonly EmotionManager? _emotionManager;
    private InterruptManager? _interruptManager;
    private readonly ResourceLoader _resourceLoader;
    private bool _isConnected = false;
    private bool _isListening = false;
    private bool _isAutoMode = false;    
    public HomePage()
    {
        this.InitializeComponent();
        _resourceLoader = new();
        
        try
        {
            _logger = App.GetService<ILogger<HomePage>>();
            _voiceChatService = App.GetService<IVoiceChatService>();
            _emotionManager = App.GetService<EmotionManager>();
            _interruptManager = App.GetService<InterruptManager>();
        }
        catch (Exception ex)
        {
            // å¦‚æœæœåŠ¡è·å–å¤±è´¥ï¼Œç»§ç»­åˆå§‹åŒ–ä½†è®°å½•é”™è¯¯
            System.Diagnostics.Debug.WriteLine($"Failed to get services: {ex.Message}");
        }

        InitializeUI();
        BindEvents();
    }    private void InitializeUI()
    {
        // åˆå§‹åŒ–çŠ¶æ€æ–‡æœ¬
        StatusText.Text = _resourceLoader.GetString("Status_Disconnected");
        ConnectionStatusText.Text = _resourceLoader.GetString("ConnectionStatus_Offline");
        TtsText.Text = _resourceLoader.GetString("TtsText_Standby");
        DefaultEmotionText.Text = "ğŸ˜Š";

        // è®¾ç½®åˆå§‹éŸ³é‡
        VolumeSlider.Value = 80;
        UpdateVolumeText(80);

        // è®¾ç½®æ‰‹åŠ¨æ¨¡å¼ä¸ºé»˜è®¤æ¨¡å¼
        SwitchToManualMode();

        // è®¾ç½®åˆå§‹è¡¨æƒ…
        SetEmotion("neutral");
    }
    private async void BindEvents()
    {
        // é¡µé¢äº‹ä»¶
        this.Unloaded += HomePage_Unloaded;

        // ç»‘å®šè¯­éŸ³æœåŠ¡äº‹ä»¶
        if (_voiceChatService != null)
        {
            _voiceChatService.DeviceStateChanged += OnDeviceStateChanged;
            _voiceChatService.VoiceChatStateChanged += OnVoiceChatStateChanged;
            _voiceChatService.MessageReceived += OnMessageReceived;
            _voiceChatService.ErrorOccurred += OnErrorOccurred;
        }

        // åˆå§‹åŒ–å’Œç»‘å®šInterruptManageräº‹ä»¶
        if (_interruptManager != null)
        {
            try
            {
                await _interruptManager.InitializeAsync();
                _interruptManager.InterruptTriggered += OnInterruptTriggered;
                _logger?.LogInformation("InterruptManager initialized successfully");
            }
            catch (Exception ex)
            {
                _logger?.LogError(ex, "Failed to initialize InterruptManager");
            }
        }
    }
    private void OnInterruptTriggered(object? sender, InterruptEventArgs e)
    {
        try
        {
            _logger?.LogInformation("Interrupt triggered: {Reason} - {Description}", e.Reason, e.Description);

            this.DispatcherQueue.TryEnqueue(async () =>
            {
                try
                {
                    await HandleInterrupt(e.Reason, e.Description);
                }
                catch (Exception ex)
                {
                    _logger?.LogError(ex, "Failed to handle interrupt in UI thread");
                    AddMessage($"å¤„ç†æ‰“æ–­æ—¶å‡ºé”™: {ex.Message}", true);
                }
            });
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to process interrupt event");
        }
    }

    private async Task HandleInterrupt(AbortReason reason, string description)
    {
        if (_voiceChatService == null)
        {
            _logger?.LogWarning("VoiceChatService is null, cannot handle interrupt");
            return;
        }

        var currentState = _voiceChatService.CurrentState;
        _logger?.LogInformation("Handling interrupt {Reason} in state {State}", reason, currentState);

        // Add user feedback message
        AddMessage($"[æ‰“æ–­] {description}", false);

        switch (reason)
        {
            case AbortReason.VoiceInterruption:
                // VAD detected user speech during AI response - abort speaking
                if (currentState == DeviceState.Speaking)
                {
                    await _voiceChatService.StopVoiceChatAsync();
                    _logger?.LogInformation("Voice chat stopped due to voice interruption");

                    // Auto-restart listening if in auto mode (like py-xiaozhi)
                    if (_voiceChatService.KeepListening)
                    {
                        // Brief delay then restart listening (matches py-xiaozhi pattern)
                        await Task.Delay(200);
                        if (_voiceChatService.CurrentState == DeviceState.Idle)
                        {
                            await _voiceChatService.StartVoiceChatAsync();
                            _logger?.LogInformation("Auto-restarted listening after voice interrupt");
                        }
                    }
                }
                break;

            case AbortReason.KeyboardInterruption:
            case AbortReason.UserInterruption:
                // F3 key or manual interrupt - handle based on current state
                switch (currentState)
                {
                    case DeviceState.Speaking:
                        // Abort current speaking
                        await _voiceChatService.StopVoiceChatAsync();
                        _logger?.LogInformation("Voice chat stopped due to user interrupt");
                        break;

                    case DeviceState.Listening:
                        // Stop listening
                        await _voiceChatService.StopVoiceChatAsync();
                        _logger?.LogInformation("Listening stopped due to user interrupt");
                        break;

                    case DeviceState.Idle:
                        // If in auto mode, this might toggle chat state (like py-xiaozhi F3 behavior)
                        if (_isAutoMode)
                        {
                            await _voiceChatService.ToggleChatStateAsync();
                            _logger?.LogInformation("Toggled chat state due to user interrupt in idle");
                        }
                        break;
                }
                break;

            case AbortReason.WakeWordDetected:
                // Wake word detected - handle like py-xiaozhi wake word behavior
                switch (currentState)
                {
                    case DeviceState.Speaking:
                        // Abort speaking and start listening
                        await _voiceChatService.StopVoiceChatAsync();
                        await Task.Delay(100); // Brief pause
                        await _voiceChatService.StartVoiceChatAsync();
                        _logger?.LogInformation("Switched from speaking to listening due to wake word");
                        break;

                    case DeviceState.Idle:
                        // Start listening
                        await _voiceChatService.StartVoiceChatAsync();
                        _logger?.LogInformation("Started listening due to wake word");
                        break;
                }
                break;

            default:
                _logger?.LogWarning("Unhandled interrupt reason: {Reason}", reason);
                break;
        }
    }

    #region äº‹ä»¶å¤„ç†

    private void OnDeviceStateChanged(object? sender, DeviceState state)
    {
        this.DispatcherQueue.TryEnqueue(() =>
        {
            // Don't update connection state based on device state!
            // DeviceState.Idle means "connected but idle", not "disconnected"
            // Connection state should only be managed by actual connection/disconnection events

            switch (state)
            {
                case DeviceState.Listening:
                    StatusText.Text = _resourceLoader.GetString("Status_Listening");
                    // Update emotion/visual indicators but don't touch connection state
                    SetEmotion("listening");
                    break;
                case DeviceState.Speaking:
                    StatusText.Text = _resourceLoader.GetString("Status_Playing");
                    // Update emotion/visual indicators but don't touch connection state
                    SetEmotion("speaking");
                    break;
                case DeviceState.Connecting:
                    StatusText.Text = _resourceLoader.GetString("Status_Connecting");
                    // Update emotion/visual indicators but don't touch connection state
                    SetEmotion("thinking");
                    break;
                case DeviceState.Idle:
                default:
                    StatusText.Text = _resourceLoader.GetString("Status_Standby");
                    // Update emotion/visual indicators but don't touch connection state
                    SetEmotion("neutral");
                    break;
            }
        });
    }
    private void OnVoiceChatStateChanged(object? sender, bool isActive)
    {
        this.DispatcherQueue.TryEnqueue(() =>
        {
            _isListening = isActive;
            UpdateUIForVoiceChatState(isActive);

            // Update auto button text when in auto mode
            if (_isAutoMode && AutoButtonText != null)
            {
                if (_voiceChatService?.KeepListening == true && _isListening)
                {
                    AutoButtonText.Text = _resourceLoader.GetString("AutoButtonText_Stop");
                }
                else if (_voiceChatService?.KeepListening == false || !_isListening)
                {
                    AutoButtonText.Text = _resourceLoader.GetString("AutoButtonText_Start");
                }
            }
        });
    }

    private void OnMessageReceived(object? sender, ChatMessage message)
    {
        this.DispatcherQueue.TryEnqueue(() =>
        {
            var displayText = message.Role switch
            {
                "user" => $"ç”¨æˆ·: {message.Content}",
                "assistant" => $"å°æ™º: {message.Content}",
                _ => message.Content
            };

            AddMessage(displayText, false);

            // å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ï¼Œæ›´æ–°TTSæ–‡æœ¬
            if (message.Role == "assistant")
            {
                TtsText.Text = message.Content;
            }
        });
    }

    private void OnErrorOccurred(object? sender, string error)
    {
        this.DispatcherQueue.TryEnqueue(() =>
        {
            AddMessage($"é”™è¯¯: {error}", true);
            _logger?.LogError("Voice chat error: {Error}", error);
        });
    }

    #endregion

    #region UIæ›´æ–°æ–¹æ³•

    private void UpdateConnectionState(bool connected)
    {
        _isConnected = connected;

        // æ›´æ–°è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨
        if (ConnectionIndicator != null)
        {
            var brush = connected ?
                Application.Current.Resources["SystemFillColorSuccessBrush"] as Microsoft.UI.Xaml.Media.Brush :
                Application.Current.Resources["SystemFillColorCriticalBrush"] as Microsoft.UI.Xaml.Media.Brush;
            if (brush != null)
            {
                ConnectionIndicator.Background = brush;
            }
        }

        // æ›´æ–°è¿æ¥çŠ¶æ€æ–‡æœ¬
        if (ConnectionStatusText != null)
        {
            ConnectionStatusText.Text = connected ? "åœ¨çº¿" : "ç¦»çº¿";
        }

        // æ›´æ–°æŒ‰é’®çŠ¶æ€
        if (ConnectButton != null)
        {
            ConnectButton.IsEnabled = !connected;
        }

        if (DisconnectButton != null)
        {
            DisconnectButton.IsEnabled = connected;
        }

        // æ›´æ–°å…¶ä»–æ§ä»¶çŠ¶æ€
        if (ManualButton != null)
        {
            ManualButton.IsEnabled = connected;
        }

        if (AutoButton != null)
        {
            AutoButton.IsEnabled = connected;
        }

        if (AbortButton != null)
        {
            AbortButton.IsEnabled = connected;
        }

        if (ModeToggleButton != null)
        {
            ModeToggleButton.IsEnabled = connected;
        }

        if (MessageTextBox != null)
        {
            MessageTextBox.IsEnabled = connected;
        }

        if (SendButton != null)
        {
            SendButton.IsEnabled = connected;
        }
    }

    private void UpdateUIForVoiceChatState(bool isActive)
    {
        if (isActive)
        {
            ShowMicrophoneVisualizer(true);
            SetEmotion("listening");
        }
        else
        {
            ShowMicrophoneVisualizer(false);
            SetEmotion("neutral");
        }
    }

    private void SwitchToManualMode()
    {
        _isAutoMode = false;
        if (ManualButton != null) ManualButton.Visibility = Visibility.Visible;
        if (AutoButton != null) AutoButton.Visibility = Visibility.Collapsed;
        if (ModeToggleText != null) ModeToggleText.Text = _resourceLoader.GetString("ModeToggleText_Manual");
    }
    private void SwitchToAutoMode()
    {
        _isAutoMode = true;
        if (ManualButton != null) ManualButton.Visibility = Visibility.Collapsed;
        if (AutoButton != null) AutoButton.Visibility = Visibility.Visible;
        if (ModeToggleText != null) ModeToggleText.Text = _resourceLoader.GetString("ModeToggleText_Auto");

        // Update button text based on current listening state and auto mode
        if (AutoButtonText != null)
        {
            if (_voiceChatService?.KeepListening == true && _isListening)            {
                AutoButtonText.Text = _resourceLoader.GetString("AutoButtonText_Stop");
            }
            else
            {
                AutoButtonText.Text = _resourceLoader.GetString("AutoButtonText_Start");
            }
        }
    }

    private void UpdateModeUI(bool isAutoMode)
    {
        _isAutoMode = isAutoMode;

        if (isAutoMode)
        {
            SwitchToAutoMode();
        }
        else
        {
            SwitchToManualMode();
        }
    }

    private void ShowMicrophoneVisualizer(bool show)
    {
        if (show)
        {
            if (VolumeControlPanel != null) VolumeControlPanel.Visibility = Visibility.Collapsed;
            if (MicVisualizerPanel != null) MicVisualizerPanel.Visibility = Visibility.Visible;
            // TODO: Start microphone level animation
        }
        else
        {
            if (VolumeControlPanel != null) VolumeControlPanel.Visibility = Visibility.Visible;
            if (MicVisualizerPanel != null) MicVisualizerPanel.Visibility = Visibility.Collapsed;
            // TODO: Stop microphone level animation
        }
    }

    private void AddMessage(string message, bool isError = false)
    {
        var textBlock = new TextBlock
        {
            Text = message,
            Margin = new Thickness(0, 4, 0, 4),
            TextWrapping = TextWrapping.Wrap,
            Foreground = isError ?
                Application.Current.Resources["SystemFillColorCriticalBrush"] as Microsoft.UI.Xaml.Media.Brush :
                Application.Current.Resources["TextFillColorPrimaryBrush"] as Microsoft.UI.Xaml.Media.Brush
        };

        // å¦‚æœå·²ç»æœ‰é»˜è®¤æ¶ˆæ¯ï¼Œæ¸…é™¤å®ƒ
        if (MessagesPanel.Children.Count > 0 &&
            MessagesPanel.Children[0] is TextBlock defaultMsg &&
            defaultMsg.Text.Contains("ç­‰å¾…å¯¹è¯å¼€å§‹"))
        {
            MessagesPanel.Children.Clear();
        }

        MessagesPanel.Children.Add(textBlock);

        // æ»šåŠ¨åˆ°åº•éƒ¨
        MessagesScrollViewer.ChangeView(null, MessagesScrollViewer.ScrollableHeight, null);
    }

    private void UpdateVolumeText(double value)
    {
        if (VolumeText != null)
        {
            VolumeText.Text = $"{(int)value}%";
        }
    }
    private void SetEmotion(string emotionName)
    {
        try
        {
            if (_emotionManager != null && DefaultEmotionText != null)
            {
                var emoji = _emotionManager.GetEmotionEmoji(emotionName);
                DefaultEmotionText.Text = emoji;
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to set emotion: {EmotionName}", emotionName);
        }
    }

    #endregion

    #region æŒ‰é’®äº‹ä»¶å¤„ç†    
    private async void ConnectButton_Click(object sender, RoutedEventArgs e)
    {
        if (_isConnected || _voiceChatService == null) return;

        try
        {
            ConnectButton.IsEnabled = false;
            StatusText.Text = _resourceLoader.GetString("Status_Connecting");
            ConnectionStatusText.Text = _resourceLoader.GetString("ConnectionStatus_Connecting");
            ConnectionIndicator.Background = Application.Current.Resources["SystemFillColorCautionBrush"] as Microsoft.UI.Xaml.Media.Brush;

            // åˆ›å»ºé…ç½®
            var config = new XiaoZhiConfig
            {
                ServerUrl = "ws://localhost:8080/ws",
                UseWebSocket = true,
                EnableVoice = true,
                AudioSampleRate = 16000,
                AudioChannels = 1,
                AudioFormat = "opus"
            };
            await _voiceChatService.InitializeAsync(config);

            // Set up wake word detector coordination (matches py-xiaozhi behavior)
            if (_interruptManager != null)
            {
                _voiceChatService.SetInterruptManager(_interruptManager);
                _logger?.LogInformation("Wake word detector coordination enabled");
            }

            // Use the service's IsConnected property to determine actual connection state
            bool isConnected = _voiceChatService.IsConnected;
            UpdateConnectionState(isConnected);

            if (isConnected)
            {
                AddMessage("è¿æ¥æˆåŠŸ");
                StatusText.Text = _resourceLoader.GetString("Status_Connected");
            }
            else
            {
                AddMessage("è¿æ¥å¤±è´¥: æœåŠ¡æœªè¿æ¥", true);
                ConnectButton.IsEnabled = true;
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to connect to voice chat service");
            AddMessage($"è¿æ¥å¤±è´¥: {ex.Message}", true);
            UpdateConnectionState(false);
            ConnectButton.IsEnabled = true;
        }
    }

    private async void DisconnectButton_Click(object sender, RoutedEventArgs e)
    {
        if (!_isConnected || _voiceChatService == null) return;

        try
        {
            DisconnectButton.IsEnabled = false;

            // åœæ­¢å½“å‰è¯­éŸ³å¯¹è¯
            if (_isListening)
            {
                await _voiceChatService.StopVoiceChatAsync();
            }

            // æ¸…ç†äº‹ä»¶è®¢é˜…
            _voiceChatService.MessageReceived -= OnMessageReceived;
            _voiceChatService.VoiceChatStateChanged -= OnVoiceChatStateChanged;
            _voiceChatService.ErrorOccurred -= OnErrorOccurred;
            _voiceChatService.DeviceStateChanged -= OnDeviceStateChanged;

            _voiceChatService.Dispose();
            // é‡ç½®æ‰€æœ‰çŠ¶æ€
            _isConnected = false;
            _isListening = false;

            AddMessage("å·²æ–­å¼€è¿æ¥");
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to disconnect from voice chat service");
            AddMessage($"æ–­å¼€è¿æ¥å¤±è´¥: {ex.Message}", true);
        }
    }

    private async void ManualButton_PointerPressed(object sender, PointerRoutedEventArgs e)
    {
        if (_voiceChatService == null || !_isConnected) return;

        try
        {
            if (!_isListening)
            {
                await _voiceChatService.StartVoiceChatAsync();
                ManualButtonText.Text = _resourceLoader.GetString("ManualButtonText_Release");
                AddMessage("å¼€å§‹å½•éŸ³ï¼Œæ¾å¼€ç»“æŸ");
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to start manual voice chat");
            AddMessage($"å¼€å§‹å½•éŸ³å¤±è´¥: {ex.Message}", true);
        }
    }

    private async void ManualButton_PointerReleased(object sender, PointerRoutedEventArgs e)
    {
        if (_voiceChatService == null || !_isConnected) return;

        try
        {
            if (_isListening)
            {
                await _voiceChatService.StopVoiceChatAsync();
                ManualButtonText.Text = _resourceLoader.GetString("ManualButtonText_Hold");
                AddMessage("å½•éŸ³ç»“æŸï¼Œæ­£åœ¨å¤„ç†...");
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to stop manual voice chat");
            AddMessage($"åœæ­¢å½•éŸ³å¤±è´¥: {ex.Message}", true);
        }
    }
    private async void AutoButton_Click(object sender, RoutedEventArgs e)
    {
        if (_voiceChatService == null || !_isConnected) return;

        try
        {
            if (!_isListening)
            {
                // Enable auto mode and start the conversation
                _voiceChatService.KeepListening = true;
                await _voiceChatService.ToggleChatStateAsync();
                AutoButtonText.Text = "åœæ­¢å¯¹è¯";
                AddMessage("è‡ªåŠ¨å¯¹è¯å·²å¼€å§‹");
            }
            else
            {
                // Disable auto mode and stop the conversation
                _voiceChatService.KeepListening = false;
                await _voiceChatService.ToggleChatStateAsync();
                AutoButtonText.Text = "å¼€å§‹å¯¹è¯";
                AddMessage("è‡ªåŠ¨å¯¹è¯å·²åœæ­¢");
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to toggle auto chat mode");
            AddMessage($"åˆ‡æ¢è‡ªåŠ¨å¯¹è¯å¤±è´¥: {ex.Message}", true);
        }
    }

    private async void AbortButton_Click(object sender, RoutedEventArgs e)
    {
        try
        {
            if (_voiceChatService != null && _isListening)
            {
                await _voiceChatService.StopVoiceChatAsync();
                AddMessage("å·²ä¸­æ–­å½“å‰æ“ä½œ");
                TtsText.Text = "å¾…å‘½";
                SetEmotion("neutral");
            }
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to abort current operation");
            AddMessage($"ä¸­æ–­æ“ä½œå¤±è´¥: {ex.Message}", true);
        }
    }

    private async void SendButton_Click(object sender, RoutedEventArgs e)
    {
        var message = MessageTextBox.Text.Trim();
        if (string.IsNullOrEmpty(message) || _voiceChatService == null || !_isConnected)
            return;

        try
        {
            AddMessage($"æˆ‘: {message}", false);
            MessageTextBox.Text = "";
            await _voiceChatService.SendTextMessageAsync(message);
        }
        catch (Exception ex)
        {
            _logger?.LogError(ex, "Failed to send text message");
            AddMessage($"å‘é€å¤±è´¥: {ex.Message}", true);
        }
    }

    private void MessageTextBox_KeyDown(object sender, KeyRoutedEventArgs e)
    {
        if (e.Key == Windows.System.VirtualKey.Enter)
        {
            SendButton_Click(sender, new RoutedEventArgs());
        }
    }

    private void ModeToggleButton_Click(object sender, RoutedEventArgs e)
    {
        _isAutoMode = !_isAutoMode;
        UpdateModeUI(_isAutoMode);
        AddMessage($"å·²åˆ‡æ¢åˆ°{(_isAutoMode ? "è‡ªåŠ¨" : "æ‰‹åŠ¨")}å¯¹è¯æ¨¡å¼");
    }

    private void VolumeSlider_ValueChanged(object sender, Microsoft.UI.Xaml.Controls.Primitives.RangeBaseValueChangedEventArgs e)
    {
        var value = e.NewValue;
        if (value < 0) return;

        UpdateVolumeText(value);
        // Note: IVoiceChatService doesn't have SetVolume method
        // if (_voiceChatService != null)
        // {
        //     _voiceChatService.SetVolume((float)(value / 100.0));
        // }
    }

    private void MuteButton_Click(object sender, RoutedEventArgs e)
    {
        var isMuted = VolumeSlider.Value == 0;

        if (isMuted)
        {
            VolumeSlider.Value = 80;
            MuteIcon.Glyph = "\uE767"; // Volume icon
        }
        else
        {
            VolumeSlider.Value = 0;
            MuteIcon.Glyph = "\uE74F"; // Mute icon
        }
    }

    #endregion

    #region é¡µé¢ç”Ÿå‘½å‘¨æœŸ

    private void HomePage_Unloaded(object sender, RoutedEventArgs e)
    {
        // æ¸…ç†äº‹ä»¶è®¢é˜…
        if (_voiceChatService != null)
        {
            _voiceChatService.DeviceStateChanged -= OnDeviceStateChanged;
            _voiceChatService.VoiceChatStateChanged -= OnVoiceChatStateChanged;
            _voiceChatService.MessageReceived -= OnMessageReceived;
            _voiceChatService.ErrorOccurred -= OnErrorOccurred;
        }
    }

    #endregion

    private void ManualButton_PointerCaptureLost(object sender, PointerRoutedEventArgs e)
    {
        ManualButton_PointerReleased(sender, null!);
    }
}